# Hadoop Environment Setup Assignment

This repository contains screenshots and documentation for setting up a Hadoop environment and installing related tools such as Java, Pig, Sqoop, MySQL, and Hive on AWS. The screenshots provided showcase the step-by-step process of setting up the environment.

## Objective

The objective of this assignment is to demonstrate proficiency in setting up a Hadoop environment and installing necessary tools for Big Data processing and analysis.

## Task

### Setup Hadoop Environment and Install Tools

1. **Connect and Update System Packages**
   ![Screenshot 1](screenshots/connect_and_update.png)
   *Description: Updating system packages after connecting to the server.*

2. **Install JDK (Java Development Kit)**
   ![Screenshot 2](screenshots/jdk_installation.png)
   ![Screenshot 3](screenshots/java_version.png)
   *Description: Installing JDK and verifying Java version.*

3. **Configure sudoers File (visudo)**
   ![Screenshot 4](screenshots/visudo.png)
   *Description: Configuring sudoers file using visudo.*

4. **Generate SSH Key for Hadoop**
   ![Screenshot 5](screenshots/hadoop_keygen.png)
   *Description: Generating SSH key for Hadoop.*

5. **Download and Extract Hadoop**
   ![Screenshot 6](screenshots/download_hadoop.png)
   ![Screenshot 7](screenshots/extract_hadoop.png)
   *Description: Downloading and extracting Hadoop distribution.*

6. **Configure Environment Variables in .bashrc File**
   ![Screenshot 8](screenshots/save_bashrcfile.png)
   *Description: Saving environment variables in .bashrc file.*

7. **Configure HDFS and Hadoop**
   ![Screenshot 9](screenshots/hdfs_hadoop_configurations.png)
   *Description: Configuring HDFS and Hadoop properties.*

8. **Start NameNode and DataNode Services**
   ![Screenshot 10](screenshots/starting_dfs_on_hadoop.png)
   *Description: Starting NameNode and DataNode services.*

9. **Format HDFS and Execute Hadoop Commands**
   ![Screenshot 11](screenshots/hdfs_namenode_format_hadoop_commands.png)
   *Description: Formatting HDFS and executing Hadoop commands.*

10. **Install Pig**
    ![Screenshot 12](screenshots/pig_install.png)
    *Description: Installing Pig for data processing.*

11. **Configure Pig in .bashrc File**
    ![Screenshot 13](screenshots/pig_config_in_bash.png)
    *Description: Configuring Pig in .bashrc file.*

12. **Execute Pig Local Command**
    ![Screenshot 14](screenshots/pig_local_command.png)
    *Description: Executing a Pig local command.*

13. **Install Sqoop and Extract**
    ![Screenshot 15](screenshots/sqoop_install_and_extract.png)
    *Description: Installing and extracting Sqoop for data import/export.*

14. **Configure Sqoop**
    ![Screenshot 16](screenshots/sqoop_config.png)
    *Description: Configuring Sqoop for data transfer.*

15. **Install MySQL Connector for Sqoop**
    ![Screenshot 17](screenshots/mysql_connector_install_for_sqoop.png)
    *Description: Installing MySQL Connector for Sqoop.*

16. **Run Sqoop Shell**
    ![Screenshot 18](screenshots/sqoop_shell.png)
    *Description: Running Sqoop shell for data transfer operations.*

17. **Install MySQL Server**
    ![Screenshot 19](screenshots/install_mysql_server.png)
    *Description: Installing MySQL server for database management.*

18. **Secure MySQL Installation**
    ![Screenshot 20](screenshots/mysql_secure_installation.png)
    *Description: Securing MySQL installation.*

19. **Verify MySQL Installation**
    ![Screenshot 21](screenshots/mysql_installation_successful.png)
    *Description: Verifying successful installation of MySQL.*

20. **Run MySQL and Execute Query**
    ![Screenshot 22](screenshots/mysql_run_and_query.png)
    *Description: Running MySQL server and executing a query.*

21. **Alter Table and Login to MySQL with Root**
    ![Screenshot 23](screenshots/alter_table_login_mysql_root.png)
    *Description: Altering table and logging in to MySQL with root.*

22. **Install Hive and Unzip**
    ![Screenshot 24](screenshots/hive_install_and_unzip.png)
    *Description: Installing and unzipping Hive for data warehousing.*

23. **Create Directory in HDFS**
    ![Screenshot 25](screenshots/hdfs_mkdir_command.png)
    *Description: Creating a directory in HDFS.*

---

This README file provides a visual walkthrough of the setup process for a Hadoop environment and installation of related tools. Each screenshot is accompanied by a description of the action taken. This documentation showcases proficiency in setting up and configuring a Hadoop ecosystem for Big Data processing on AWS.
